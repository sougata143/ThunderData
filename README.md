# ThunderData: Advanced Text Processing Toolkit

A comprehensive data engineering application with advanced natural language processing capabilities to transform and analyze text data efficiently. Built with React frontend and FastAPI backend.

## ğŸš€ Features

### Text Processing Capabilities
- **Tokenization**: Split text into individual tokens
- **Stopword Removal**: Remove common stopwords from text
- **Lemmatization**: Convert words to their base/dictionary form
- **Text Vectorization**: Convert text to numerical vectors (TF-IDF and Count Vectorization)
- **Named Entity Recognition**: Extract named entities (e.g., Person, Organization, Location)
- **Part of Speech Tagging**: Identify grammatical parts of speech
- **Stemming**: Reduce words to their root/stem form

### Technical Features
- **Real-time Processing Status**: Track file processing progress with detailed status updates
- **Batch Processing**: Handle large datasets efficiently with configurable batch sizes
- **Flexible Input/Output**: Support for multiple file formats (CSV, JSON, TXT, XLSX)
- **Error Handling**: Comprehensive error handling with detailed error messages
- **Validation**: Input validation with file type and size constraints
- **Asynchronous Processing**: Background task processing for large files
- **RESTful API**: Well-documented API endpoints for all operations

## ğŸ› ï¸ Project Structure

```
ThunderData/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ processor.py
â”‚   â”‚   â”œâ”€â”€ schemas/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â””â”€â”€ processing.py
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ status.py
â”‚   â”‚   â”‚   â””â”€â”€ validation.py
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ uploads/
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ FileUpload.js
â”‚   â”‚   â”‚   â”œâ”€â”€ ProcessingStatus.js
â”‚   â”‚   â”‚   â””â”€â”€ TransformationConfig.js
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ App.js
â”‚   â”‚   â””â”€â”€ index.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ README.md
â””â”€â”€ README.md
```

## ğŸ”§ Technical Requirements

### Backend
- Python 3.11+
- FastAPI
- Uvicorn
- Pandas
- NumPy
- SpaCy (with en_core_web_sm model)
- scikit-learn
- NLTK

### Frontend
- Node.js 16+
- React 18+
- Axios for API calls
- Material-UI for components

## ğŸš¦ API Endpoints

- `POST /api/upload`: Upload file for processing
- `POST /api/process/{file_id}`: Process file with specified transformations
- `GET /api/status/{file_id}`: Get processing status
- `GET /api/download/{filename}`: Download processed file

## ğŸ’» Development Setup

1. Clone the repository
```bash
git clone https://github.com/yourusername/ThunderData.git
cd ThunderData
```

2. Set up backend
```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt
python -m spacy download en_core_web_sm
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

3. Set up frontend
```bash
cd frontend
npm install
npm start
```

## ğŸ”’ Validation Constraints

- Supported file types: .csv, .json, .txt, .xlsx
- Maximum file size: 100MB
- Batch processing with configurable batch size
- Strict transformation type and parameter validation

## ğŸŒŸ Future Improvements

- Support for more language models
- Enhanced vectorization techniques
- More advanced NLP transformations
- Improved frontend configuration UI
- Real-time text analysis
- Custom transformation pipeline builder
- Export configurations for reproducibility
- Parallel processing for large datasets

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
